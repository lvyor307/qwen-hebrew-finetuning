{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32fd46a6-068b-4bef-8655-139cfef67aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [openpyxl]1/2\u001b[0m [openpyxl]\n",
      "\u001b[1A\u001b[2KSuccessfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98403fea-bcd6-451e-97cf-9ff0fb2c10b3",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65e5a565-045e-4e49-8196-9130a592be47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu, SmoothingFunction\n",
    "from nltk.translate.meteor_score import meteor_score as meteor_score_func\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab7d547-3a18-4f38-9587-0f0d1c42e7dd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Evaluate Translation - Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43a8ac46-3b83-48c8-9d3a-d9410f23f9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_meteor_score(references, candidates):\n",
    "    scores = []\n",
    "    for i in range(len(references)):\n",
    "        scores.append(meteor_score_func(references[i], candidates[i]))\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "102afe92-b453-41a0-8851-37364221283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_n(references, candidates, n, w=None, s=None):\n",
    "    scores = []\n",
    "    acc_for_small = []\n",
    "    okay = []\n",
    "    for i in range(len(references)):\n",
    "        a = references[i]\n",
    "        b = candidates[i]\n",
    "        if len(a[0]) < n or len(b) < n:\n",
    "            okay.append(False)\n",
    "            acc_for_small.append(' '.join(a[0]) == ' '.join(b))\n",
    "        else:\n",
    "            okay.append(True)\n",
    "            scores.append(sentence_bleu(a, b, weights=w, smoothing_function=s))\n",
    "\n",
    "    corpus_score = corpus_bleu(pd.Series(references)[okay], pd.Series(candidates)[okay], weights=w, smoothing_function=s)\n",
    "    return np.mean(scores), np.mean(acc_for_small), corpus_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af3e5b6e-9f38-4919-aada-9a9718bfc970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_eval(original, fixed, n_grams=[2, 3, 4, 6], smoother=SmoothingFunction().method4, logging_bleu=False):\n",
    "    eval_dct = {}\n",
    "    cols = ['answer_1', 'answer_2', 'answer_3', 'answer_4']\n",
    "\n",
    "    eval_dct['Semantic maintaining'] = 1 - fixed['Semantic_Inequality'].mean()\n",
    "    eval_dct['Gender maintaining'] = 1 - fixed['Gender_mismatch'].mean()\n",
    "\n",
    "    # Exact same questions num\n",
    "    eval_dct['untouched acc question'] = (original['question'] == fixed['question']).mean()\n",
    "    # Exact same answers num\n",
    "    answers_original = pd.Series([i for c in cols for i in original[c].values])\n",
    "    answers_fixed = pd.Series([i for c in cols for i in fixed[c].values])\n",
    "    eval_dct['untouched acc answers'] = (answers_original == answers_fixed).mean()\n",
    "\n",
    "    # Calcualte BLEU score\n",
    "    bleu_weights = [[1/i] * i for i in n_grams]\n",
    "    n_gram_str = [f'BLEU-{i}' for i in n_grams]\n",
    "\n",
    "    # BLUE score on questions\n",
    "    references_question = [[i.split()] for i in fixed['question'].values]\n",
    "    candidates_question = [i.split() for i in original['question'].values]\n",
    "    score = [sentence_bleu(x, y, weights=bleu_weights, smoothing_function=smoother) for x, y in zip(references_question, candidates_question)]\n",
    "    score = np.array(score).mean(axis=0)\n",
    "    corpus_score = corpus_bleu(references_question, candidates_question, weights=bleu_weights, smoothing_function=smoother)\n",
    "\n",
    "    # METEOR score on questions\n",
    "    meteor_score = [meteor_score_func(x, y) for x, y in zip(references_question, candidates_question)]\n",
    "    meteor_score = np.array(meteor_score).mean(axis=0)\n",
    "    \n",
    "    # BLEU score on answers\n",
    "    references_answers = [[i.split()] for c in cols for i in fixed[c].values]\n",
    "    candidates_answers = [i.split() for c in cols for i in original[c].values]\n",
    "    score_answers = []\n",
    "    acc_small = []\n",
    "    corpus_score_answers = []\n",
    "    for i in range(len(n_grams)):\n",
    "        output = bleu_n(references_answers, candidates_answers, n_grams[i], bleu_weights[i], smoother)\n",
    "        score_answers.append(output[0])\n",
    "        acc_small.append(output[1])\n",
    "        corpus_score_answers.append(output[2])\n",
    "\n",
    "    # METEOR score on answers\n",
    "    meteor_score_answers = calc_meteor_score(references_answers, candidates_answers)\n",
    "\n",
    "    # Enter results to output\n",
    "    eval_dct['BLEU'] = {}\n",
    "    for n, s, sa in zip(n_grams, score, score_answers):\n",
    "        eval_dct['BLEU'][f'questions_BLEU_{n}'] = s\n",
    "        eval_dct['BLEU'][f'answers_BLEU_{n}'] = sa\n",
    "    \n",
    "    eval_dct['METEOR'] = {}\n",
    "    eval_dct['METEOR']['questions_METEOR'] = meteor_score\n",
    "    eval_dct['METEOR']['answers_METEOR'] = meteor_score_answers\n",
    "\n",
    "    if logging_bleu:\n",
    "        print(f'Questions: Corpus  [{\", \".join(n_gram_str)}] score: {np.round(corpus_score, 4)}')\n",
    "        print(f'Questions: Average [{\", \".join(n_gram_str)}] score: {np.round(score, 4)}')\n",
    "        print()\n",
    "        print(f'Answers: Average   [{\", \".join(n_gram_str)}] score: {np.round(score_answers, 4)}')\n",
    "        print(f'Answers: ACC@small [{\", \".join(n_gram_str)}] score: {np.round(acc_small, 4)}')\n",
    "        print(f'Answers: Corpus    [{\", \".join(n_gram_str)}] score: {np.round(corpus_score_answers, 4)}')\n",
    "\n",
    "    return eval_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "103433cf-93dd-4165-a3fd-18a625ad9da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert value to color\n",
    "def color_gradient(val):\n",
    "    g = int(255 * val ** 2)\n",
    "    r = 255 - g\n",
    "    return f'background-color: rgb({r}, {g}, 0)'\n",
    "\n",
    "\n",
    "def show_eval_dct(eval_dct):\n",
    "    # Create the DataFrame to show:\n",
    "    a = pd.DataFrame(eval_dct, index=['value']).drop(['BLEU', 'METEOR'], axis=1)\n",
    "    b = pd.DataFrame(eval_dct['BLEU'], index=['value'])\n",
    "    c = pd.DataFrame(eval_dct['METEOR'], index=['value'])\n",
    "    d = pd.concat([a, b, c], axis=1)\n",
    "    \n",
    "    # Apply the color styling\n",
    "    styled_df = d.style.format('{:.3f}').map(color_gradient)\n",
    "    display(styled_df)\n",
    "\n",
    "\n",
    "def print_eval_dct(eval_dct):\n",
    "    for k in eval_dct:\n",
    "        if type(eval_dct[k]) is not dict:\n",
    "            print(f'{k:26} | {eval_dct[k]:7.3f}')\n",
    "        if k == 'BLEU':\n",
    "            print('BLEU scores:')\n",
    "            for bk in eval_dct[k]:\n",
    "                print(f'\\t{bk:18} | {eval_dct[k][bk]:7.3f}')\n",
    "        if k == 'METEOR':\n",
    "            print('METEOR scores:')\n",
    "            for bk in eval_dct[k]:\n",
    "                print(f'\\t{bk:18} | {eval_dct[k][bk]:7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fb84459-1bd2-488b-b0aa-f7a53628708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_where_different(original, fixed):\n",
    "    # + 5 - the first five rows are the few-shots exampels\n",
    "    # + 2 - the first row in the excel file is the columns' names, and the index starts with 1\n",
    "    question_different = original.index[original['question'] != fixed['question']] + 2 + 5\n",
    "\n",
    "    change_set = set()\n",
    "    change_set |= set(original.index[original['answer_1'] != fixed['answer_1']] + 2 + 5)\n",
    "    change_set |= set(original.index[original['answer_2'] != fixed['answer_2']] + 2 + 5)\n",
    "    change_set |= set(original.index[original['answer_3'] != fixed['answer_3']] + 2 + 5)\n",
    "    change_set |= set(original.index[original['answer_4'] != fixed['answer_4']] + 2 + 5)\n",
    "    \n",
    "    change_set = list(change_set)\n",
    "    change_set = sorted(change_set)\n",
    "    answers_different = change_set\n",
    "\n",
    "    output = {\n",
    "        'questions': question_different,\n",
    "        'answers': answers_different,\n",
    "    }\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a714b37a-6574-4a78-9b53-074f0a0221d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Evaluate Translation - Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba8e2e80-0c09-46d1-9148-df9a7018f6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_excel('translate_eval/claude_arc_ai2_chall_train_subsample - Original.xlsx', index_col='Unnamed: 0')\n",
    "fixed    = pd.read_excel('translate_eval/claude_arc_ai2_chall_train_subsample - fixed.xlsx', index_col='Unnamed: 0')\n",
    "# First five exmaples are from the few-shots in the prompt, remove them\n",
    "original = original.iloc[5:].reset_index(drop=True)\n",
    "fixed = fixed.iloc[5:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19897de1-806b-40bb-8b3a-b35dc42705b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'questions': Index([ 7, 11, 17, 22, 27, 28, 35, 38, 39, 41, 43, 44, 48, 51, 54, 55, 56, 60,\n",
       "        63, 66, 69, 71, 73, 74, 75, 77, 78, 80, 81],\n",
       "       dtype='int64'),\n",
       " 'answers': [14, 17, 20, 26, 27, 33, 54, 57, 64, 78, 81]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dif = get_where_different(original, fixed)\n",
    "dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fc02c88-89fe-49bd-a730-95d46ad5858d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bf4c7_row0_col0 {\n",
       "  background-color: rgb(14, 241, 0);\n",
       "}\n",
       "#T_bf4c7_row0_col1, #T_bf4c7_row0_col6 {\n",
       "  background-color: rgb(46, 209, 0);\n",
       "}\n",
       "#T_bf4c7_row0_col2 {\n",
       "  background-color: rgb(160, 95, 0);\n",
       "}\n",
       "#T_bf4c7_row0_col3 {\n",
       "  background-color: rgb(30, 225, 0);\n",
       "}\n",
       "#T_bf4c7_row0_col4 {\n",
       "  background-color: rgb(37, 218, 0);\n",
       "}\n",
       "#T_bf4c7_row0_col5 {\n",
       "  background-color: rgb(15, 240, 0);\n",
       "}\n",
       "#T_bf4c7_row0_col7 {\n",
       "  background-color: rgb(25, 230, 0);\n",
       "}\n",
       "#T_bf4c7_row0_col8 {\n",
       "  background-color: rgb(55, 200, 0);\n",
       "}\n",
       "#T_bf4c7_row0_col9 {\n",
       "  background-color: rgb(36, 219, 0);\n",
       "}\n",
       "#T_bf4c7_row0_col10 {\n",
       "  background-color: rgb(74, 181, 0);\n",
       "}\n",
       "#T_bf4c7_row0_col11 {\n",
       "  background-color: rgb(47, 208, 0);\n",
       "}\n",
       "#T_bf4c7_row0_col12 {\n",
       "  background-color: rgb(26, 229, 0);\n",
       "}\n",
       "#T_bf4c7_row0_col13 {\n",
       "  background-color: rgb(61, 194, 0);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bf4c7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bf4c7_level0_col0\" class=\"col_heading level0 col0\" >Semantic maintaining</th>\n",
       "      <th id=\"T_bf4c7_level0_col1\" class=\"col_heading level0 col1\" >Gender maintaining</th>\n",
       "      <th id=\"T_bf4c7_level0_col2\" class=\"col_heading level0 col2\" >untouched acc question</th>\n",
       "      <th id=\"T_bf4c7_level0_col3\" class=\"col_heading level0 col3\" >untouched acc answers</th>\n",
       "      <th id=\"T_bf4c7_level0_col4\" class=\"col_heading level0 col4\" >questions_BLEU_2</th>\n",
       "      <th id=\"T_bf4c7_level0_col5\" class=\"col_heading level0 col5\" >answers_BLEU_2</th>\n",
       "      <th id=\"T_bf4c7_level0_col6\" class=\"col_heading level0 col6\" >questions_BLEU_3</th>\n",
       "      <th id=\"T_bf4c7_level0_col7\" class=\"col_heading level0 col7\" >answers_BLEU_3</th>\n",
       "      <th id=\"T_bf4c7_level0_col8\" class=\"col_heading level0 col8\" >questions_BLEU_4</th>\n",
       "      <th id=\"T_bf4c7_level0_col9\" class=\"col_heading level0 col9\" >answers_BLEU_4</th>\n",
       "      <th id=\"T_bf4c7_level0_col10\" class=\"col_heading level0 col10\" >questions_BLEU_6</th>\n",
       "      <th id=\"T_bf4c7_level0_col11\" class=\"col_heading level0 col11\" >answers_BLEU_6</th>\n",
       "      <th id=\"T_bf4c7_level0_col12\" class=\"col_heading level0 col12\" >questions_METEOR</th>\n",
       "      <th id=\"T_bf4c7_level0_col13\" class=\"col_heading level0 col13\" >answers_METEOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bf4c7_level0_row0\" class=\"row_heading level0 row0\" >value</th>\n",
       "      <td id=\"T_bf4c7_row0_col0\" class=\"data row0 col0\" >0.973</td>\n",
       "      <td id=\"T_bf4c7_row0_col1\" class=\"data row0 col1\" >0.907</td>\n",
       "      <td id=\"T_bf4c7_row0_col2\" class=\"data row0 col2\" >0.613</td>\n",
       "      <td id=\"T_bf4c7_row0_col3\" class=\"data row0 col3\" >0.940</td>\n",
       "      <td id=\"T_bf4c7_row0_col4\" class=\"data row0 col4\" >0.926</td>\n",
       "      <td id=\"T_bf4c7_row0_col5\" class=\"data row0 col5\" >0.971</td>\n",
       "      <td id=\"T_bf4c7_row0_col6\" class=\"data row0 col6\" >0.906</td>\n",
       "      <td id=\"T_bf4c7_row0_col7\" class=\"data row0 col7\" >0.951</td>\n",
       "      <td id=\"T_bf4c7_row0_col8\" class=\"data row0 col8\" >0.887</td>\n",
       "      <td id=\"T_bf4c7_row0_col9\" class=\"data row0 col9\" >0.928</td>\n",
       "      <td id=\"T_bf4c7_row0_col10\" class=\"data row0 col10\" >0.843</td>\n",
       "      <td id=\"T_bf4c7_row0_col11\" class=\"data row0 col11\" >0.904</td>\n",
       "      <td id=\"T_bf4c7_row0_col12\" class=\"data row0 col12\" >0.949</td>\n",
       "      <td id=\"T_bf4c7_row0_col13\" class=\"data row0 col13\" >0.873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fdeaa0ea2c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic maintaining       |   0.973\n",
      "Gender maintaining         |   0.907\n",
      "untouched acc question     |   0.613\n",
      "untouched acc answers      |   0.940\n",
      "BLEU scores:\n",
      "\tquestions_BLEU_2   |   0.926\n",
      "\tanswers_BLEU_2     |   0.971\n",
      "\tquestions_BLEU_3   |   0.906\n",
      "\tanswers_BLEU_3     |   0.951\n",
      "\tquestions_BLEU_4   |   0.887\n",
      "\tanswers_BLEU_4     |   0.928\n",
      "\tquestions_BLEU_6   |   0.843\n",
      "\tanswers_BLEU_6     |   0.904\n",
      "METEOR scores:\n",
      "\tquestions_METEOR   |   0.949\n",
      "\tanswers_METEOR     |   0.873\n",
      "CPU times: user 118 ms, sys: 3.08 ms, total: 121 ms\n",
      "Wall time: 120 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "eval_dct = calculate_eval(original, fixed)\n",
    "show_eval_dct(eval_dct)\n",
    "print_eval_dct(eval_dct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504401aa-0ad9-465d-9ae3-1d438fd85161",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Evaluate Translation - dictalm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd01db5d-c4ec-4b24-8199-87bf247c3398",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_excel('translate_eval/dicta_arc_ai2_challenge_train_subsample - Original.xlsx', index_col='Unnamed: 0')\n",
    "fixed    = pd.read_excel('translate_eval/dicta_arc_ai2_challenge_train_subsample - fixed.xlsx', index_col='Unnamed: 0')\n",
    "# First five exmaples are from the few-shots in the prompt, remove them\n",
    "original = original.iloc[5:].reset_index(drop=True)\n",
    "fixed = fixed.iloc[5:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8539d06-15ab-44ce-b830-dfeee8f6cb9a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'questions': Index([12, 19, 21, 22, 25, 26, 27, 29, 38, 41, 42, 43, 48, 51, 63, 69, 75, 77,\n",
       "        78, 81],\n",
       "       dtype='int64'),\n",
       " 'answers': [7,\n",
       "  8,\n",
       "  18,\n",
       "  26,\n",
       "  41,\n",
       "  45,\n",
       "  50,\n",
       "  51,\n",
       "  56,\n",
       "  59,\n",
       "  63,\n",
       "  66,\n",
       "  67,\n",
       "  70,\n",
       "  71,\n",
       "  72,\n",
       "  78,\n",
       "  81]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dif = get_where_different(original, fixed)\n",
    "dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b026762b-c32e-4849-b3e4-c966ebb24c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bace2_row0_col0 {\n",
       "  background-color: rgb(76, 179, 0);\n",
       "}\n",
       "#T_bace2_row0_col1 {\n",
       "  background-color: rgb(40, 215, 0);\n",
       "}\n",
       "#T_bace2_row0_col2 {\n",
       "  background-color: rgb(118, 137, 0);\n",
       "}\n",
       "#T_bace2_row0_col3 {\n",
       "  background-color: rgb(57, 198, 0);\n",
       "}\n",
       "#T_bace2_row0_col4 {\n",
       "  background-color: rgb(23, 232, 0);\n",
       "}\n",
       "#T_bace2_row0_col5 {\n",
       "  background-color: rgb(39, 216, 0);\n",
       "}\n",
       "#T_bace2_row0_col6 {\n",
       "  background-color: rgb(27, 228, 0);\n",
       "}\n",
       "#T_bace2_row0_col7 {\n",
       "  background-color: rgb(42, 213, 0);\n",
       "}\n",
       "#T_bace2_row0_col8 {\n",
       "  background-color: rgb(32, 223, 0);\n",
       "}\n",
       "#T_bace2_row0_col9 {\n",
       "  background-color: rgb(61, 194, 0);\n",
       "}\n",
       "#T_bace2_row0_col10 {\n",
       "  background-color: rgb(44, 211, 0);\n",
       "}\n",
       "#T_bace2_row0_col11 {\n",
       "  background-color: rgb(66, 189, 0);\n",
       "}\n",
       "#T_bace2_row0_col12 {\n",
       "  background-color: rgb(16, 239, 0);\n",
       "}\n",
       "#T_bace2_row0_col13 {\n",
       "  background-color: rgb(80, 175, 0);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bace2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bace2_level0_col0\" class=\"col_heading level0 col0\" >Semantic maintaining</th>\n",
       "      <th id=\"T_bace2_level0_col1\" class=\"col_heading level0 col1\" >Gender maintaining</th>\n",
       "      <th id=\"T_bace2_level0_col2\" class=\"col_heading level0 col2\" >untouched acc question</th>\n",
       "      <th id=\"T_bace2_level0_col3\" class=\"col_heading level0 col3\" >untouched acc answers</th>\n",
       "      <th id=\"T_bace2_level0_col4\" class=\"col_heading level0 col4\" >questions_BLEU_2</th>\n",
       "      <th id=\"T_bace2_level0_col5\" class=\"col_heading level0 col5\" >answers_BLEU_2</th>\n",
       "      <th id=\"T_bace2_level0_col6\" class=\"col_heading level0 col6\" >questions_BLEU_3</th>\n",
       "      <th id=\"T_bace2_level0_col7\" class=\"col_heading level0 col7\" >answers_BLEU_3</th>\n",
       "      <th id=\"T_bace2_level0_col8\" class=\"col_heading level0 col8\" >questions_BLEU_4</th>\n",
       "      <th id=\"T_bace2_level0_col9\" class=\"col_heading level0 col9\" >answers_BLEU_4</th>\n",
       "      <th id=\"T_bace2_level0_col10\" class=\"col_heading level0 col10\" >questions_BLEU_6</th>\n",
       "      <th id=\"T_bace2_level0_col11\" class=\"col_heading level0 col11\" >answers_BLEU_6</th>\n",
       "      <th id=\"T_bace2_level0_col12\" class=\"col_heading level0 col12\" >questions_METEOR</th>\n",
       "      <th id=\"T_bace2_level0_col13\" class=\"col_heading level0 col13\" >answers_METEOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bace2_level0_row0\" class=\"row_heading level0 row0\" >value</th>\n",
       "      <td id=\"T_bace2_row0_col0\" class=\"data row0 col0\" >0.840</td>\n",
       "      <td id=\"T_bace2_row0_col1\" class=\"data row0 col1\" >0.920</td>\n",
       "      <td id=\"T_bace2_row0_col2\" class=\"data row0 col2\" >0.733</td>\n",
       "      <td id=\"T_bace2_row0_col3\" class=\"data row0 col3\" >0.883</td>\n",
       "      <td id=\"T_bace2_row0_col4\" class=\"data row0 col4\" >0.955</td>\n",
       "      <td id=\"T_bace2_row0_col5\" class=\"data row0 col5\" >0.920</td>\n",
       "      <td id=\"T_bace2_row0_col6\" class=\"data row0 col6\" >0.946</td>\n",
       "      <td id=\"T_bace2_row0_col7\" class=\"data row0 col7\" >0.915</td>\n",
       "      <td id=\"T_bace2_row0_col8\" class=\"data row0 col8\" >0.936</td>\n",
       "      <td id=\"T_bace2_row0_col9\" class=\"data row0 col9\" >0.873</td>\n",
       "      <td id=\"T_bace2_row0_col10\" class=\"data row0 col10\" >0.910</td>\n",
       "      <td id=\"T_bace2_row0_col11\" class=\"data row0 col11\" >0.863</td>\n",
       "      <td id=\"T_bace2_row0_col12\" class=\"data row0 col12\" >0.968</td>\n",
       "      <td id=\"T_bace2_row0_col13\" class=\"data row0 col13\" >0.830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fdeab1b1ab0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic maintaining       |   0.840\n",
      "Gender maintaining         |   0.920\n",
      "untouched acc question     |   0.733\n",
      "untouched acc answers      |   0.883\n",
      "BLEU scores:\n",
      "\tquestions_BLEU_2   |   0.955\n",
      "\tanswers_BLEU_2     |   0.920\n",
      "\tquestions_BLEU_3   |   0.946\n",
      "\tanswers_BLEU_3     |   0.915\n",
      "\tquestions_BLEU_4   |   0.936\n",
      "\tanswers_BLEU_4     |   0.873\n",
      "\tquestions_BLEU_6   |   0.910\n",
      "\tanswers_BLEU_6     |   0.863\n",
      "METEOR scores:\n",
      "\tquestions_METEOR   |   0.968\n",
      "\tanswers_METEOR     |   0.830\n",
      "CPU times: user 128 ms, sys: 3.51 ms, total: 131 ms\n",
      "Wall time: 131 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "eval_dct = calculate_eval(original, fixed)\n",
    "show_eval_dct(eval_dct)\n",
    "print_eval_dct(eval_dct)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
