{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de8480e5-c3d0-40b2-884c-66c86a21dfde",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (20.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.33.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.12.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.6.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub>=0.24.0->datasets)\n",
      "  Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Downloading aiohttp-3.12.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading multidict-6.6.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (242 kB)\n",
      "Downloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (222 kB)\n",
      "Downloading huggingface_hub-0.33.1-py3-none-any.whl (515 kB)\n",
      "Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m156.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (198 kB)\n",
      "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Installing collected packages: xxhash, propcache, multidict, hf-xet, fsspec, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
      "\u001b[2K  Attempting uninstall: fsspec\n",
      "\u001b[2K    Found existing installation: fsspec 2025.5.1\n",
      "\u001b[2K    Uninstalling fsspec-2025.5.1:\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.5.1\n",
      "\u001b[2K  Attempting uninstall: dill\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/15\u001b[0m [fsspec]\n",
      "\u001b[2K    Found existing installation: dill 0.4.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/15\u001b[0m [fsspec]\n",
      "\u001b[2K    Uninstalling dill-0.4.0:\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/15\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled dill-0.4.0━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/15\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: multiprocess0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/15\u001b[0m [dill]\n",
      "\u001b[2K    Found existing installation: multiprocess 0.70.18━━━━━━━━━\u001b[0m \u001b[32m 6/15\u001b[0m [dill]\n",
      "\u001b[2K    Uninstalling multiprocess-0.70.18:m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/15\u001b[0m [dill]\n",
      "\u001b[2K      Successfully uninstalled multiprocess-0.70.18━━━━━━━━━━━\u001b[0m \u001b[32m 6/15\u001b[0m [dill]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/15\u001b[0m [datasets]/15\u001b[0m [datasets]ce-hub]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pathos 0.3.4 requires dill>=0.4.0, but you have dill 0.3.8 which is incompatible.\n",
      "pathos 0.3.4 requires multiprocess>=0.70.18, but you have multiprocess 0.70.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.13 aiosignal-1.3.2 async-timeout-5.0.1 datasets-3.6.0 dill-0.3.8 frozenlist-1.7.0 fsspec-2025.3.0 hf-xet-1.1.5 huggingface-hub-0.33.1 multidict-6.6.2 multiprocess-0.70.16 propcache-0.3.2 xxhash-3.5.0 yarl-1.20.1\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [openpyxl]1/2\u001b[0m [openpyxl]\n",
      "\u001b[1A\u001b[2KSuccessfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install openpyxl\n",
    "!pip install -q -U google-genai\n",
    "# !pip install transformers\n",
    "# !pip install accelerate\n",
    "# !pip install peft\n",
    "# !pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52ac5aa-eb0a-4ae5-b8de-a5d2a6fbc453",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c5c1afb-bf91-456d-aecd-63dbe731d117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('qwen-hebrew-finetuning/translation/')\n",
    "\n",
    "# Call models\n",
    "from src.call_models import bedrock_connect, call_claude_bedrock\n",
    "from src.call_models import google_connect, call_gemini, all_string_gemini_config, all_int_gemini_config\n",
    "from src.translate_func import claude_translation, gemini_translation, gemini_multi_translation, gemini_claude_best_translation\n",
    "\n",
    "# Datasets\n",
    "from src.benchmarks_code import arc_ai\n",
    "from prompts import arc_prompts\n",
    "\n",
    "from my_access_keys import google_access_key, aws_access_key, aws_secret_key\n",
    "\n",
    "# Remove annoying warning\n",
    "from IPython.core.display_functions import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d558c746-5323-449a-9715-0787c26e8144",
   "metadata": {},
   "source": [
    "# Check Models Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b0fa69c7-ab51-4646-b912-1c7b1679c558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claude:\n",
      "היווצרות יבשת העל פנגיאה\n"
     ]
    }
   ],
   "source": [
    "bedrock_client = bedrock_connect(aws_access_key, aws_secret_key)\n",
    "\n",
    "print('claude:')\n",
    "print(call_claude_bedrock(bedrock_client, 'Which one is more accurate in Hebrew? repeat the right sentence, without adding anything\\nהיווצרות יבשת העל פנגיאה OR היווצרות היבשת העל פנגיאה'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56199320-be49-4ac8-996e-b42def67ce67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini:\n",
      "{\n",
      "  \"recipe\": \"CLASSIC CHOCOLATE CHIP COOKIES\",\n",
      "  \"ingredients\": \"2 1/4 CUPS ALL-PURPOSE FLOUR, 1 TEASPOON BAKING SODA, 1 TEASPOON SALT, 1 CUP (2 STICKS) UNSALTED BUTTER, SOFTENED, 3/4 CUP GRANULATED SUGAR, 3/4 CUP PACKED BROWN SUGAR, 1 TEASPOON VANILLA EXTRACT, 2 LARGE EGGS, 2 CUPS (12-OZ. PKG.) SEMISWEET CHOCOLATE CHIPS, 1 CUP CHOPPED NUTS (OPTIONAL)\"\n",
      "}\n",
      "---\n",
      "dict_keys(['recipe', 'ingredients'])\n"
     ]
    }
   ],
   "source": [
    "google_client = google_connect(google_access_key)\n",
    "\n",
    "print('Gemini:')\n",
    "generate_content_config = all_string_gemini_config(['recipe', 'ingredients'], 'USE ONLY ALLCAPS')\n",
    "response = call_gemini(google_client, \"List a popular cookie recipe, and include the amounts of ingredients.\", generate_content_config)\n",
    "print(response.text)\n",
    "print('---')\n",
    "my_recipes = response.parsed\n",
    "print(my_recipes.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e9b7c3-0fe6-4d38-9f14-11dbc22c4407",
   "metadata": {},
   "source": [
    "# ARC_AI2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f8b0ca-de73-46c6-908d-35f288bb3c16",
   "metadata": {},
   "source": [
    "## Get Datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc1f8efc-d4cb-4b6e-b88c-7b3ef27d2f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c0544458814358a89d6bd4bbec9fd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aafa9823161493aa226808b20cd3700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ARC-Challenge/train-00000-of-00001.parqu(…):   0%|          | 0.00/190k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842c0e90580d48ad802bb2673ebaf735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ARC-Challenge/test-00000-of-00001.parque(…):   0%|          | 0.00/204k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c7aacf652945e089370430562de4df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ARC-Challenge/validation-00000-of-00001.(…):   0%|          | 0.00/55.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c7eb0fb3b62439d8330bb8adebce669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1119 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a78644486e124261b041e02667a7c019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1172 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e828c5c7b1499bb3c10c0331defc70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/299 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'arc_challenge_train': Dataset({\n",
       "     features: ['id', 'question', 'choices', 'answerKey'],\n",
       "     num_rows: 1119\n",
       " })}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arc_dataset = arc_ai.get_arc_ai2_datasets()\n",
    "arc_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f98916f6-e29b-46ba-be1f-01891c949744",
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_dataset['arc_challenge_train'] = arc_dataset['arc_challenge_train'].skip(5).take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99689ffe-aeb2-4137-a1bd-40c09782cdac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arc_challenge_train': Dataset({\n",
       "     features: ['id', 'question', 'choices', 'answerKey'],\n",
       "     num_rows: 2\n",
       " })}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arc_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8e00e11-7b22-4f57-b94b-d9c19ed143ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Which land form is the result of the constructive force of a glacier?',\n",
       " 'option 1': 'valleys carved by a moving glacier',\n",
       " 'option 2': 'piles of rocks deposited by a melting glacier',\n",
       " 'option 3': 'grooves created in a granite surface by a glacier',\n",
       " 'option 4': 'bedrock hills roughened by the passing of a glacier'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arc_ai.arc_sample_to_dict(arc_dataset['arc_challenge_train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0110eefb-aab4-451d-b273-b0d5a554c91f",
   "metadata": {},
   "source": [
    "## Run Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f09840-3fa3-4124-8feb-a52d8cb213f9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3434cdc0-2da8-4654-8a92-31c95a7e3e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating arc_challenge_train...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32741c4bf2eb4b3cab366f46ae73accd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call to Claude took 4.83[seconds]\n",
      "4551\n",
      "Call to Claude took 8.19[seconds]\n",
      "4722\n"
     ]
    }
   ],
   "source": [
    "hebrew_datasets = claude_translation(\n",
    "    bedrock_client,\n",
    "    arc_dataset,\n",
    "    arc_prompts.ARC_INSTRUCT,\n",
    "    arc_prompts.ARC_FEW_SHOTS,\n",
    "    arc_prompts.ARC_FORMAT,\n",
    "    arc_ai.arc_sample_to_dict,\n",
    "    arc_ai.arc_dict_to_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "41226840-6582-4f76-9322-af3ccb567b00",
   "metadata": {},
   "source": [
    "Call to Claude took 4.83[seconds]\n",
    "4551\n",
    "Call to Claude took 8.19[seconds]\n",
    "4722"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ea60d6-15d6-4115-98b2-498847e90da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(arc_dataset['arc_challenge_train'][0])\n",
    "print()\n",
    "display(arc_dataset['arc_challenge_train'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ebcf958-b661-48ea-b574-fe4cb19637a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'Mercury_SC_401653',\n",
       " 'question': 'איזו צורת נוף היא תוצאה של הכוח הבונה של קרחון?',\n",
       " 'choices': {'label': ['א', 'ב', 'ג', 'ד'],\n",
       "  'text': ['עמקים שנחצבו על ידי קרחון נע',\n",
       "   'ערימות של סלעים שהושקעו על ידי קרחון נמס',\n",
       "   'חריצים שנוצרו במשטח גרניט על ידי קרחון',\n",
       "   'גבעות סלע יסוד שהתחספסו ממעבר של קרחון']},\n",
       " 'answerKey': 'ב'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'MEA_2016_8_14',\n",
       " 'question': 'איזה היגד משווה בצורה הטובה ביותר בין אורגניזמים חד-תאיים לרב-תאיים?',\n",
       " 'choices': {'label': ['א', 'ב', 'ג', 'ד'],\n",
       "  'text': ['רקמות באורגניזם חד-תאי דומות לתאים באורגניזם רב-תאי.',\n",
       "   'הגרעין באורגניזם חד-תאי דומה לעור של אורגניזם רב-תאי.',\n",
       "   'אברונים באורגניזם חד-תאי דומים לאיברים באורגניזם רב-תאי.',\n",
       "   'הציטופלזמה באורגניזם חד-תאי דומה למערכת העצבים באורגניזם רב-תאי.']},\n",
       " 'answerKey': 'ג'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(hebrew_datasets['arc_challenge_train'][0])\n",
    "print()\n",
    "display(hebrew_datasets['arc_challenge_train'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb78fe76-0542-4e88-bfcc-6225757ebc1f",
   "metadata": {},
   "source": [
    "### Multi-options Translation - Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542488c0-ebc1-48cd-8493-ba1bfbe286c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def claude_multi_translation(bedrock_client, datasets, instruct, few_shots, sample_format, sample_to_dict, dict_to_sample):\n",
    "    \"\"\"\n",
    "    Translate all given datasets using one of the claude famaliy models.\n",
    "    \"\"\"\n",
    "    # The final prompt for the models\n",
    "    final_prompt = instruct + '\\n\\n' + few_shots + '\\n\\n' + sample_format + '\\n\\n'\n",
    "    hebrew_dataset = {}\n",
    "    # Run on the different splits in the dataset\n",
    "    for key in datasets:\n",
    "        print(f'Translating {key}...')\n",
    "        hebrew_dataset[key] = []\n",
    "        # Run on all the split's samples\n",
    "        for sample in tqdm(datasets[key], total=datasets[key].num_rows):\n",
    "            # from sample to dict\n",
    "            dct = sample_to_dict(sample)\n",
    "\n",
    "            # Enter into prompt\n",
    "            samples_query = '\\n'.join([f'<{k}>{dct[k]}</{k}>' for k in dct])\n",
    "            query = final_prompt + BASE_PROMPT.format(X=samples_query, Y='')\n",
    "\n",
    "            # Call claude\n",
    "            output = call_claude_bedrock(bedrock_client, query)\n",
    "\n",
    "            # Parse the model's output\n",
    "            pattern = r\"<([^>]+)>(.*?)</\\1>\"\n",
    "            matches = re.findall(pattern, output, re.DOTALL)\n",
    "            result = {key: value.strip() for key, value in matches}\n",
    "\n",
    "            # Create New sample\n",
    "            new_sample = dict_to_sample(sample, result)\n",
    "            hebrew_dataset[key].append(new_sample)\n",
    "\n",
    "        hebrew_dataset[key] = Dataset.from_list(hebrew_dataset[key])\n",
    "    return hebrew_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1a501e-f0e0-4897-a3d2-f922f52d9719",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6dcc499b-39ce-46ae-b20f-e1e0ce44fd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating arc_challenge_train...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df22345848914af9bf5a7f8bce04eb80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hebrew_datasets = gemini_translation(\n",
    "    google_client,\n",
    "    arc_dataset,\n",
    "    arc_prompts.ARC_INSTRUCT,\n",
    "    arc_prompts.ARC_FEW_SHOTS,\n",
    "    arc_ai.arc_sample_to_dict,\n",
    "    arc_ai.arc_dict_to_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "722d93bf-87ee-4ea8-863f-644bcc263d45",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'Mercury_SC_401653',\n",
       " 'question': 'Which land form is the result of the constructive force of a glacier?',\n",
       " 'choices': {'text': ['valleys carved by a moving glacier',\n",
       "   'piles of rocks deposited by a melting glacier',\n",
       "   'grooves created in a granite surface by a glacier',\n",
       "   'bedrock hills roughened by the passing of a glacier'],\n",
       "  'label': ['A', 'B', 'C', 'D']},\n",
       " 'answerKey': 'B'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'MEA_2016_8_14',\n",
       " 'question': 'Which statement best compares single-celled and multi-celled organisms?',\n",
       " 'choices': {'text': ['Tissues in a single-celled organism are like the cells in a multi-celled organism.',\n",
       "   'The nucleus in a single-celled organism is like the skin of a multi-celled organism.',\n",
       "   'Organelles in a single-celled organism are like the organs in a multi-celled organism.',\n",
       "   'The cytoplasm in a single-celled organism is like the nervous system in a multi-celled organism.'],\n",
       "  'label': ['A', 'B', 'C', 'D']},\n",
       " 'answerKey': 'C'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(arc_dataset['arc_challenge_train'][0])\n",
    "print()\n",
    "display(arc_dataset['arc_challenge_train'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "464c42cb-0964-4b02-b635-d1ca23a470d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'Mercury_SC_401653',\n",
       " 'question': 'איזו צורת נוף היא תוצאה של הכוח הבונה של קרחון?',\n",
       " 'choices': {'label': ['א', 'ב', 'ג', 'ד'],\n",
       "  'text': ['עמקים שנחרצו על ידי קרחון נע',\n",
       "   'ערימות סלעים שהושקעו על ידי קרחון נמס',\n",
       "   'חריצים שנוצרו במשטח גרניט על ידי קרחון',\n",
       "   'גבעות סלע אם שהוחלקו על ידי מעבר של קרחון']},\n",
       " 'answerKey': 'ב'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'MEA_2016_8_14',\n",
       " 'question': 'איזו טענה משווה בצורה הטובה ביותר אורגניזמים חד-תאיים ורב-תאיים?',\n",
       " 'choices': {'label': ['א', 'ב', 'ג', 'ד'],\n",
       "  'text': ['רקמות באורגניזם חד-תאי דומות לתאים באורגניזם רב-תאי.',\n",
       "   'הגרעין באורגניזם חד-תאי דומה לעור של אורגניזם רב-תאי.',\n",
       "   'אברונים באורגניזם חד-תאי דומים לאיברים באורגניזם רב-תאי.',\n",
       "   'הציטופלזמה באורגניזם חד-תאי דומה למערכת העצבים באורגניזם רב-תאי.']},\n",
       " 'answerKey': 'ג'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(hebrew_datasets['arc_challenge_train'][0])\n",
    "print()\n",
    "display(hebrew_datasets['arc_challenge_train'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1691522-c65b-44ef-9bd4-3a8eefa04c3a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Multi-options Translation - Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "150eb3a5-ae0a-40c0-8325-fcc4c4a861fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your task is to translate the given English question and possible answers into possible Hebrew translations. Follow these guidelines:\n",
      "\n",
      "1. Only translate the question and answer options provided. Do not add any additional text or instructions.\n",
      "2. Preserve the original semantic meaning and intent of the question and answers as accurately as possible in the Hebrew translation.\n",
      "3. Maintain the same formatting and style as the original English version.\n",
      "4. Provide three possible translations for the question and each one of the answers.\n",
      "5. Provide the Hebrew translation immediately after these instructions, without any preamble or additional context.\n"
     ]
    }
   ],
   "source": [
    "print(arc_prompts.ARC_INSTRUCT_MULTI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ccaea7b1-aadf-416a-8a18-73506becba74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating arc_challenge_train...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d4717606254a2f8e3e28af6386da2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hebrew_datasets = gemini_multi_translation(\n",
    "    google_client,\n",
    "    arc_dataset,\n",
    "    arc_prompts.ARC_INSTRUCT_MULTI,\n",
    "    arc_prompts.ARC_FEW_SHOTS,\n",
    "    arc_ai.arc_sample_to_dict,\n",
    "    arc_ai.arc_dict_to_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7f33a43b-2f27-450e-8d6c-c94b4ac49da4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'Mercury_SC_401653',\n",
       " 'question': 'Which land form is the result of the constructive force of a glacier?',\n",
       " 'choices': {'text': ['valleys carved by a moving glacier',\n",
       "   'piles of rocks deposited by a melting glacier',\n",
       "   'grooves created in a granite surface by a glacier',\n",
       "   'bedrock hills roughened by the passing of a glacier'],\n",
       "  'label': ['A', 'B', 'C', 'D']},\n",
       " 'answerKey': 'B'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'MEA_2016_8_14',\n",
       " 'question': 'Which statement best compares single-celled and multi-celled organisms?',\n",
       " 'choices': {'text': ['Tissues in a single-celled organism are like the cells in a multi-celled organism.',\n",
       "   'The nucleus in a single-celled organism is like the skin of a multi-celled organism.',\n",
       "   'Organelles in a single-celled organism are like the organs in a multi-celled organism.',\n",
       "   'The cytoplasm in a single-celled organism is like the nervous system in a multi-celled organism.'],\n",
       "  'label': ['A', 'B', 'C', 'D']},\n",
       " 'answerKey': 'C'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(arc_dataset['arc_challenge_train'][0])\n",
    "print()\n",
    "display(arc_dataset['arc_challenge_train'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d268d267-b278-40de-89aa-43037d966ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'Mercury_SC_401653',\n",
       " 'question': 'איזו צורת נוף נוצרת כתוצאה מכוח בונה של קרחון?',\n",
       " 'choices': {'label': ['א', 'ב', 'ג', 'ד'],\n",
       "  'text': ['עמקים שנחרצו על ידי קרחון נע.',\n",
       "   'ערימות סלעים שהושקעו על ידי קרחון נמס.',\n",
       "   'חריצים שנוצרו במשטח גרניט על ידי קרחון.',\n",
       "   'גבעות סלע ששופשפו על ידי קרחון חולף.']},\n",
       " 'answerKey': 'ב'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'MEA_2016_8_14',\n",
       " 'question': 'איזו טענה משווה בצורה הטובה ביותר אורגניזמים חד-תאיים ורב-תאיים?',\n",
       " 'choices': {'label': ['א', 'ב', 'ג', 'ד'],\n",
       "  'text': ['רקמות באורגניזם חד-תאי דומות לתאים באורגניזם רב-תאי.',\n",
       "   'הגרעין באורגניזם חד-תאי דומה לעור באורגניזם רב-תאי.',\n",
       "   'אברונים באורגניזם חד-תאי דומים לאיברים באורגניזם רב-תאי.',\n",
       "   'הציטופלזמה באורגניזם חד-תאי דומה למערכת העצבים באורגניזם רב-תאי.']},\n",
       " 'answerKey': 'ג'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(hebrew_datasets['arc_challenge_train'][0])\n",
    "print()\n",
    "display(hebrew_datasets['arc_challenge_train'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3844fb4b-f71b-4f7c-82ef-57c51f3e3f76",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e140d41-d017-45f2-8c56-d71f50d7a905",
   "metadata": {},
   "source": [
    "original, hebrew = gemini_multi_translation(\n",
    "    google_client,\n",
    "    arc_dataset,\n",
    "    arc_prompts.ARC_INSTRUCT_MULTI,\n",
    "    arc_prompts.ARC_FEW_SHOTS,\n",
    "    arc_ai.arc_sample_to_dict,\n",
    "    arc_ai.arc_dict_to_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "65643b31-67b8-4264-8849-ccf7ab4c7198",
   "metadata": {},
   "source": [
    "original, hebrew"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f741f3dc-1cb4-4e9f-840e-39d61c97d71e",
   "metadata": {},
   "source": [
    "from src.translate_func import CHOOSE_INSTRUCT, options_to_prompt\n",
    "choose_config = all_string_gemini_config(original.keys(), system_instruction=CHOOSE_INSTRUCT)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ddc46e88-2391-4902-8e18-5c68a8ec7697",
   "metadata": {},
   "source": [
    "q = options_to_prompt(original, hebrew)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ca79d4e-6ff7-4d01-801a-0ae0b28866cf",
   "metadata": {},
   "source": [
    "output = call_gemini(google_client, q, choose_config)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7edc1461-db21-40f5-adaa-f4db0910c0a2",
   "metadata": {},
   "source": [
    "output.parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851254f5-cfbf-462e-98dd-3338614ff9ef",
   "metadata": {},
   "source": [
    "### Claude vs Gemini (using Gemini as judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "97657086-d183-4ab9-b3fd-3c86bf7fb34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating arc_challenge_train...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6fc870d14a4be291bd0978a2e7065f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hebrew_datasets = gemini_claude_best_translation(\n",
    "    google_client,\n",
    "    bedrock_client,\n",
    "    arc_dataset,\n",
    "    arc_prompts.ARC_INSTRUCT,\n",
    "    arc_prompts.ARC_FEW_SHOTS,\n",
    "    arc_prompts.ARC_FORMAT,\n",
    "    arc_ai.arc_sample_to_dict,\n",
    "    arc_ai.arc_dict_to_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6236cbf1-9b29-4afe-952c-d91daeb5b4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(arc_dataset['arc_challenge_train'][0])\n",
    "print()\n",
    "display(arc_dataset['arc_challenge_train'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b0131784-523f-4f64-8ff6-148a71cfa8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'Mercury_SC_401653',\n",
       " 'question': 'איזו צורת קרקע היא תוצאה של הכוח הבונה של קרחון?',\n",
       " 'choices': {'label': ['א', 'ב', 'ג', 'ד'],\n",
       "  'text': ['עמקים שנחצבו על ידי קרחון נע',\n",
       "   'ערימות של סלעים שהושקעו על ידי קרחון נמס',\n",
       "   'חריצים שנוצרו במשטח גרניט על ידי קרחון',\n",
       "   'גבעות סלע יסוד שהתחספסו בעקבות מעבר קרחון']},\n",
       " 'answerKey': 'ב',\n",
       " 'Translated Model': 'Claude'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'MEA_2016_8_14',\n",
       " 'question': 'איזה היגד משווה בצורה הטובה ביותר בין אורגניזמים חד-תאיים לרב-תאיים?',\n",
       " 'choices': {'label': ['א', 'ב', 'ג', 'ד'],\n",
       "  'text': ['רקמות באורגניזם חד-תאי דומות לתאים באורגניזם רב-תאי.',\n",
       "   'הגרעין באורגניזם חד-תאי דומה לעור של אורגניזם רב-תאי.',\n",
       "   'האברונים באורגניזם חד-תאי דומים לאיברים באורגניזם רב-תאי.',\n",
       "   'הציטופלזמה באורגניזם חד-תאי דומה למערכת העצבים באורגניזם רב-תאי.']},\n",
       " 'answerKey': 'ג',\n",
       " 'Translated Model': 'Claude'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(hebrew_datasets['arc_challenge_train'][0])\n",
    "print()\n",
    "display(hebrew_datasets['arc_challenge_train'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07d9e0c-b42c-4330-9e43-22385f859b0c",
   "metadata": {},
   "source": [
    "### to csv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3940e93d-ffa2-4e86-89e2-6cb01060155f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "source": [
    "few_hebrew_dataset = {}\n",
    "few_hebrew_dataset = []\n",
    "for example in tqdm(datasets['arc_ai2'].take(5), total=5):\n",
    "    few_hebrew_dataset.append(translate_claude(example, prompt, base_prompt, into_arc_prompt, back_to_arc))\n",
    "few_hebrew_dataset = Dataset.from_list(few_hebrew_dataset)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da4ec977-4cb6-414b-8a7e-ff507118f69d",
   "metadata": {},
   "source": [
    "df = pd.DataFrame(b)\n",
    "df['label'] = df['choices'].apply(lambda x: x['label'])\n",
    "df['text'] = df['choices'].apply(lambda x: x['text'])\n",
    "df[[f'answer_{i}' for i in range(1, 5)]] = df['text'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a5ea120-ce42-417d-a696-61e860ee74f0",
   "metadata": {},
   "source": [
    "df.drop(['choices', 'text'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dec53e43-04c1-4083-8181-ba5555a4b585",
   "metadata": {},
   "source": [
    "df.to_csv('claude_arc_ai2_chall_val_subsample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296388da-d4fb-4b36-a2db-1c57f951882e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# GSM8K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7199e18c-20c5-43c0-8927-207ededa0f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"<instruction>\n",
    "Your task is to translate the given English question and answer into Hebrew, following these guidelines:\n",
    "\n",
    "<guidelines>\n",
    "1. Only translate the provided question and answer. Do not add any additional text or instructions.\n",
    "2. Preserve the original meaning and intent of the question and answer as accurately as possible in the Hebrew translation.\n",
    "3. Maintain the same structure and formatting as the original English version, including bullet points, numbering, or other formatting elements.\n",
    "</guidelines>\n",
    "\n",
    "<example_format>\n",
    "Provide the Hebrew translation immediately after these instructions in the following format:\n",
    "\n",
    "<question>\n",
    "Translated question\n",
    "</question>\n",
    "<answer>\n",
    "Translated answer\n",
    "</answer>\n",
    "</example_format>\n",
    "</instruction>\n",
    "\n",
    "<fewshot_examples>\n",
    "<example>\n",
    "English:\n",
    "<question>\n",
    "In April, Tank gathered 10 more Easter eggs than Emma in their first round of egg hunt. However, Emma gathered twice as many eggs as Tank in their second round of egg hunt, while Tank's total number of eggs in the second round was 20 less than the number she had gathered in the first round. If the total number of eggs in the pile they were collecting with 6 other people was 400 eggs, and Emma gathered 60 eggs in the second egg hunt round, find the number of eggs that the 6 other egg hunters collected?\n",
    "</question>\n",
    "<answer>\n",
    "Tank's total number of eggs in the second round was 60/2=<<60/2=30>>30 since Emma gathered twice as many eggs as Tank in their second round of egg hunt.\n",
    "The total number of eggs that Emma and Tank gathered in the second round was 60+30=<<60+30=90>>90\n",
    "Tank's total number of eggs in the second round was 20 less than the number she had gathered in the first round, meaning she had gathered 30+20=<<30+20=50>>50 eggs in the first round of egg hunt.\n",
    "Tank gathered 10 more Easter eggs than Emma in their first round of egg hunt, meaning Emma collected 50-10=40 eggs\n",
    "The total number of eggs Emma and Tank collected in the first round was 40+50=<<40+50=90>>90\n",
    "In the two rounds, Emma and Tank gathered 90+90=<<90+90=180>>180 eggs\n",
    "If the total number of eggs in the pile they were collecting with 6 other people was 400 eggs, the six other people gathered 400-180=<<400-180=220>>220 eggs\n",
    "#### 220\n",
    "</answer>\n",
    "\n",
    "Hebrew:\n",
    "<question>\n",
    "באפריל, טאנק אספה 10 ביצי פסחא יותר מאמה בסבב הראשון של ציד ביצים. עם זאת, אמה אספה פי שניים ביצים מטאנק בסבב השני של ציד ביצים, בעוד שהמספר הכולל של הביצים של טאנק בסבב השני היה 20 פחות מהמספר שהיא אספה בסבב הראשון. אם המספר הכולל של הביצים בערימה שהן אספו יחד עם 6 אנשים נוספים היה 400 ביצים, ואמה אספה 60 ביצים בסבב השני של ציד ביצים, מצאו את מספר הביצים שאספו 6 ציידי הביצים האחרים?\n",
    "</question>\n",
    "<answer>\n",
    "מספר ביצי הפסחא הכולל של טאנק בסיבוב השני היה 60/2=<<60/2=30>>30 מכיוון שאמה אספה פי שניים ביצי פסחא מטנק בסיבוב השני שלהן בציד הביצים.\n",
    "מספר ביצי הפסחא הכולל שאמה וטאנק אספו בסיבוב השני היה 60+30=<<60+30=90>>90\n",
    "מספר ביצי הפסחא הכולל של טאנק בסיבוב השני היה 20 פחות ממספר הביצים שהיא אספה בסיבוב הראשון, כלומר היא אספה 30+20=<<30+20=50>>50 ביצי פסחא בסיבוב הראשון של ציד הביצים.\n",
    "טאנק אספה 10 ביצי פסחא יותר מאמה בסיבוב הראשון שלהן בציד הביצים, כלומר אמה אספה 50-10=40 ביצי פסחא\n",
    "מספר ביצי הפסחא הכולל שאמה וטאנק אספו בסיבוב הראשון היה 40+50=<<40+50=90>>90\n",
    "בשני הסיבובים, אמה וטאנק אספו 90+90=<<90+90=180>>180 ביצי פסחא\n",
    "אם המספר הכולל של ביצי הפסחא בערימה שהן אספו יחד עם 6 אנשים אחרים היה 400 ביצים, ששת האנשים האחרים אספו 400-180=<<400-180=220>>220 ביצי פסחא\n",
    "#### 220\n",
    "</answer>\n",
    "</example>\n",
    "</fewshot_examples>\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
